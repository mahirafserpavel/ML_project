{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "d2fz0YWF-kh_",
        "F-vKQiK1-N8E",
        "vDADXBXQL9Y-"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Lung ðŸ« cancer Prediction using Machine Learning Techniques*** \n",
        "\n",
        "---\n",
        "---\n",
        "We are proposing a machine-learning model to predict the level of lung cancer. Our goal is to create an efficient machine-learning model to predict the risk level of the lung by using available features such as index, Patient Id, Age, Gender, Air Pollution, Alcohol use, Dust Allergy, Occupational Hazards, Genetic Risk, Chronic Lung Disease, Balanced Diet, Obesity, Smoking, Passive Smoker and so on.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tL-ACdNX4Y0L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "> **Importing libraries**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "TClmgYnBziUk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rZltopPeunO"
      },
      "outputs": [],
      "source": [
        "# importing libraries\n",
        "import pandas as pd # data processing\n",
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt # visualization\n",
        "import graphviz\n",
        "\n",
        "%matplotlib inline\n",
        "from IPython.display import Image\n",
        "from itertools import product\n",
        "import seaborn as sns\n",
        "# increases the size of sns plots\n",
        "sns.set(rc={'figure.figsize':(8,6)})\n",
        "from sklearn.linear_model import Lasso,LassoCV,LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "from sklearn.feature_selection import RFE \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score,GridSearchCV\n",
        "from sklearn import tree\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, r2_score, roc_curve, auc, classification_report, roc_auc_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler,MaxAbsScaler,RobustScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Mounting google drive**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4EsoGwZY9fVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "L3W_4Xpke4K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Accessing dataset available in the google drive and exploring the dataset.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lfQI7IEn9zFM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# raw data in panda dataframe\n",
        "df = pd.read_csv('/content/drive/MyDrive/CSE499/cancer-patient-data-sets.csv')\n",
        "print('Data Frame Shape: \\n{}'.format(df.shape))\n",
        "# shows five instances of the dataframe\n",
        "print('First few instances of the dataset: ')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "FVw3p7e1e4-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# columns of the dataset\n",
        "df.columns"
      ],
      "metadata": {
        "id": "2hezhazjf16C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# investigating all the elements whithin each Feature\n",
        "for column in df:\n",
        "  unique_vals = df[column].unique()\n",
        "  nr_values = len(unique_vals)\n",
        "  \n",
        "  if nr_values < 10:\n",
        "    print('The number of values for feature {} :{} -- {}'.format(column, nr_values,unique_vals))\n",
        "  else:\n",
        "    print('The number of values for feature {} :{}'.format(column, nr_values))"
      ],
      "metadata": {
        "id": "mWz06kqRgDQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# ***Data preprocessing*** \n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "We want to preprocess data with some tasks like checking null values, converting data types, watching the importance of features by Pearson correlation, the Lasso Regression model, and Recursive Feature Elimination."
      ],
      "metadata": {
        "id": "d2fz0YWF-kh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for the null values\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "f_NlcnkOgK2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data types\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "i4Vxj_gpgYwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out all the features with type object\n",
        "objectList = df.select_dtypes(include = \"object\").columns\n",
        "print (objectList)"
      ],
      "metadata": {
        "id": "QcraqaHkg0U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**We want to do label Encoding to convert categorical data to numeric data. So, all the instances will be numerical.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "um60mOWn0rPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding for object to numeric conversion\n",
        "encoder = LabelEncoder()\n",
        "\n",
        "for obj in objectList:\n",
        "    df[obj] = encoder.fit_transform(df[obj].astype(str))\n",
        "\n",
        "print (df.info())"
      ],
      "metadata": {
        "id": "zND8PbzChUg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting new dataframe as csv\n",
        "df.to_csv('/content/drive/MyDrive/CSE499/cancer-patient-data-sets(labelencoded).csv')"
      ],
      "metadata": {
        "id": "jCgzV9okhjgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# separating attributes and target\n",
        "attribute = df.drop(columns = ['Level'])\n",
        "target = df['Level']\n",
        "print('Attribute Shape: ', attribute.shape)\n",
        "print('Target Shape: ', target.shape)"
      ],
      "metadata": {
        "id": "dJTw0RxPiIjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing the target variable to check if it blanaced or imbalanced\n",
        "target.value_counts()"
      ],
      "metadata": {
        "id": "OeBKRpqpiXpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first few instances of attribute\n",
        "attribute.head()"
      ],
      "metadata": {
        "id": "sjLuKBMTidR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first few instances of target\n",
        "target.head()"
      ],
      "metadata": {
        "id": "wXPNQ_Xgis2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test splitting(70% for training & 30% for testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(attribute, target, train_size = 0.7, test_size = 0.3, random_state = 0)"
      ],
      "metadata": {
        "id": "p2Ofd-nBiy6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('For training: ')\n",
        "print('Attribute Shape: ', X_train.shape)\n",
        "print('Target Shape: ', y_train.shape)\n",
        "\n",
        "print('\\nFor testing: ')\n",
        "print('Attribute Shape: ', X_test.shape)\n",
        "print('Target Shape: ', y_test.shape)"
      ],
      "metadata": {
        "id": "BaJ99j4Si3ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using pearson correlation\n",
        "plt.figure(figsize=(25, 25))\n",
        "correlation = df.corr()\n",
        "sns.heatmap(correlation, annot=True, cmap=plt.cm.CMRmap_r)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3TN0vcWYi9--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print the top most important features accordingly(excluding the target variable)\n",
        "corr_abs = abs(correlation['Level'])  \n",
        "corr_abs_sorted = corr_abs.sort_values(ascending=False)  \n",
        "print('Most important features:\\n', corr_abs_sorted[1:26])  "
      ],
      "metadata": {
        "id": "EGaRC-3eDB8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Lasso Regression model to the data\n",
        "lasso_cv = LassoCV(cv=5)\n",
        "lasso_cv.fit(X_train, y_train)\n",
        "\n",
        "# Print the optimal value of alpha\n",
        "print(\"Optimal alpha:\", lasso_cv.alpha_)\n"
      ],
      "metadata": {
        "id": "wdUoPV35UE7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Lasso Regression model to the data\n",
        "lasso = Lasso(alpha=lasso_cv.alpha_)\n",
        "lasso.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "9ptTGzpQqp9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the coefficients of the Lasso model\n",
        "for i in range(len(lasso.coef_)):\n",
        "    print(f\"Feature : {X_train.columns[i]}, Coefficient values: {lasso.coef_[i]:.2f}\")"
      ],
      "metadata": {
        "id": "w-TVa9HzxCEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the feature importances\n",
        "plt.figure(figsize=(25,5))\n",
        "plt.bar(range(len(lasso.coef_)), lasso.coef_)\n",
        "plt.xticks(range(len(lasso.coef_)), [f\"{X_train.columns[i]}\" for i in range(len(lasso.coef_))], rotation=90)\n",
        "plt.title(\"Lasso Regression Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OutlTLkTxDp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a logistic regression estimator\n",
        "estimator = LogisticRegression()\n",
        "\n",
        "# Create a Recursive Feature Elimination (RFE) object\n",
        "rfe = RFE(estimator)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_features_to_select': [5, 10, 15],\n",
        "    'step': [1, 2, 3]\n",
        "}\n",
        "\n",
        "# Perform a grid search with cross-validation\n",
        "grid_search = GridSearchCV(rfe, param_grid, cv=10)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and corresponding score\n",
        "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
        "print(\"Best score:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "K4639Uw6sQ6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Recursive Feature Elimination (RFE) object with best hyperparameters\n",
        "rfe = RFE(estimator, n_features_to_select=10, step=1)\n",
        "\n",
        "# Fit the RFE object to the data\n",
        "rfe.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "_TGrLxwPWA4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the ranking of each feature\n",
        "print(\"Feature rankings:\")\n",
        "for i in range(len(rfe.ranking_)):\n",
        "    print(f\"Feature :'{X_train.columns[i]}', ranking: {rfe.ranking_[i]}\")"
      ],
      "metadata": {
        "id": "XA-QbV9qxatn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the feature importances\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(len(rfe.ranking_)), rfe.ranking_)\n",
        "plt.xticks(range(len(rfe.ranking_)), [f\"{X_train.columns[i]}\" for i in range(len(rfe.ranking_))], rotation=90)\n",
        "plt.title(\"RFE Feature Ranking\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4cV4yBiqxdhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**After Data preprocessing, We want to remove the 'index' & 'Patient Id ' features. Because of the uniqueness of these features, They can be Noisy or Overfitting. Lack of variability is another issue here.**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QqJYaYSi2BVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing two columns (index and patient id)\n",
        "new_df = df.drop(columns = ['index','Patient Id'])\n",
        "print('New Data Frame Shape: ', new_df.shape)"
      ],
      "metadata": {
        "id": "ZntcbBCrBf-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# exporting new dataframe as csv\n",
        "new_df.to_csv('/content/drive/MyDrive/CSE499/cancer-patient-data-sets(filtered).csv')"
      ],
      "metadata": {
        "id": "Gf0QCKlVByPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Exploring new Dataset**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VgecyxIy5J8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# separating attributes and target\n",
        "attribute = new_df.drop(columns = ['Level'])\n",
        "target = new_df['Level']\n",
        "print('Attribute Shape: ', attribute.shape)\n",
        "print('Target Shape: ', target.shape)"
      ],
      "metadata": {
        "id": "GoZifFbB7oZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#70% for training and 30% for testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(attribute, target, train_size = 0.7, test_size = 0.3, random_state = 0)"
      ],
      "metadata": {
        "id": "JOHKaKyX8Es_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('For training: ')\n",
        "print('Attribute Shape: ', X_train.shape)\n",
        "print('Target Shape: ', y_train.shape)\n",
        "\n",
        "print('\\nFor testing: ')\n",
        "print('Attribute Shape: ', X_test.shape)\n",
        "print('Target Shape: ', y_test.shape)"
      ],
      "metadata": {
        "id": "wwMND5i-8Kpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# ***Decision Tree*** \n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "We want to run the \"Decision Tree\" classifier in the dataset. Initially, we will train the model without the best hypermeters. Later then, We will process it with the best hypermeters."
      ],
      "metadata": {
        "id": "F-vKQiK1-N8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Model\n",
        "dtree = DecisionTreeClassifier()\n",
        "dtree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "HjWDP-B68OYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "**The Below code will generate the .dot file of the graph. Using this file, we can export the image that is available in the posted link:** \n",
        "*`https://dreampuf.github.io/GraphvizOnline`*\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_NGmyR6y_fhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph available in: https://dreampuf.github.io/GraphvizOnline\n",
        "\n",
        "dot_data = tree.export_graphviz(dtree, out_file='/content/drive/MyDrive/CSE499/Decision tree.dot')\n",
        "feature_names = new_df.drop('Level', axis=1).columns,\n",
        "class_names = new_df['Level'].unique().astype(str)\n",
        "graph = graphviz.Source(dot_data)\n"
      ],
      "metadata": {
        "id": "bjT7Uq5b8Yxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generating Image\n",
        "Image(filename='/content/drive/MyDrive/CSE499/graphviz.png')"
      ],
      "metadata": {
        "id": "M4okNxBUDJWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Calculating the training and Testing Accuracy of the Model**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "FuZP_P_TBovg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Accuracy Of Decision Tree\n",
        "print(\"Training Accuracy is: \", dtree.score(X_train, y_train))\n",
        "# Test Accuracy Of Decision Tree\n",
        "print(\"Testing Accuracy is: \", dtree.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "KF2pg8vGD4SM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**After Model training, We want to check importance of each feature's**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "o57g_lJEB-5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding importance of each feature\n",
        "\n",
        "for i, column in enumerate(new_df.drop('Level', axis=1)):\n",
        "  print('Importance of feature {}:, {:.3f}'.format(column, dtree.feature_importances_[i]))\n",
        "  feature_imp = pd.DataFrame({'Variable': [column], 'Feature Importance Score': [dtree.feature_importances_[i]]})\n",
        "\n",
        "  try:\n",
        "    final_feature_imp = pd.concat([final_feature_imp, feature_imp], ignore_index = True)\n",
        "  except:\n",
        "    final_feature_imp = feature_imp\n",
        "\n",
        "# Ordering the data\n",
        "final_feature_imp = final_feature_imp.sort_values('Feature Importance Score', ascending = False).reset_index()\n",
        "final_feature_imp"
      ],
      "metadata": {
        "id": "u1hjb5INENfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**We select to apply 10-fold and 5-fold cross-validation to see if we find different results**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fLEfXn-8Cghv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# after applying 10 fold cross validation\n",
        "kfold_validation = KFold(n_splits = 10)\n",
        "results = cross_val_score(dtree, attribute, target, cv = kfold_validation)\n",
        "print(results)\n",
        "print ('\\nResults = ', np.mean(results), '+/-', np.std(results))"
      ],
      "metadata": {
        "id": "4EC4lbZDEr8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after applying 5 fold cross validation\n",
        "kfold_validation = KFold(n_splits = 5)\n",
        "results = cross_val_score(dtree, attribute, target, cv = kfold_validation)\n",
        "print(results)\n",
        "print ('\\nResults = ', np.mean(results), '+/-', np.std(results))"
      ],
      "metadata": {
        "id": "JWaacd2XUT8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**We will try to find the best hyperparameters. Using grid search, we will tune the Hyperparameters.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "kQTiPxMoDMmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'criterion': ['gini', 'entropy'],\n",
        "              'max_depth': [2, 4, 6, 8, 10],\n",
        "              'min_samples_split': [2, 5, 10],\n",
        "              'min_samples_leaf': [1, 2, 4],\n",
        "              'max_features': ['auto', 'sqrt', 'log2']}\n",
        "\n",
        "grid = GridSearchCV(dtree, param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "print(\"Best hyperparameters:\", grid.best_params_)\n",
        "print(\"Best score:\", grid.best_score_)\n",
        "best_model = grid.best_estimator_\n",
        "best_model.score(X_test, y_test)\n"
      ],
      "metadata": {
        "id": "5MN6A5aFFhmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**We will apply these parameters to process the Model again. It is listed below:**\n",
        "\n",
        "\n",
        "`{'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2}`\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "Q5Gl65Q2D9Xm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Model\n",
        "dtree = DecisionTreeClassifier(criterion = 'gini', max_depth = 6, max_features = 'auto', min_samples_leaf = 1, min_samples_split = 2)\n",
        "dtree.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "aBGskkERGTsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graph available in: https://dreampuf.github.io/GraphvizOnline\n",
        "dot_data = tree.export_graphviz(dtree, out_file='/content/drive/MyDrive/CSE499/Decision tree(Another).dot')\n",
        "feature_names = new_df.drop('Level', axis=1).columns,\n",
        "class_names = new_df['Level'].unique().astype(str)\n",
        "graph = graphviz.Source(dot_data)"
      ],
      "metadata": {
        "id": "qHvLitYWHgw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Print The graph\n",
        "Image(filename='/content/drive/MyDrive/CSE499/DT.png')"
      ],
      "metadata": {
        "id": "0TD4xmTYHnih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Accuracy Of Decision Tree\n",
        "print(\"Training Accuracy is: \", dtree.score(X_train, y_train))\n",
        "# Test Accuracy Of Decision Tree\n",
        "print(\"Testing Accuracy is: \", dtree.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "nIjtqHP3JAjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "**Initially, Training and Testing Accuracy was 100%. After processing with the best Hyperparameters we got 97.42% for training and 96.00% for testing.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "H0lTYwmeGl9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding importance of each feature\n",
        "\n",
        "for i, column in enumerate(new_df.drop('Level', axis=1)):\n",
        "  print('Importance of feature {}:, {:.3f}'.format(column, dtree.feature_importances_[i]))\n",
        "  feature_imp = pd.DataFrame({'Variable': [column], 'Feature Importance Score': [dtree.feature_importances_[i]]})\n",
        "\n",
        "  try:\n",
        "    final_feature_imp = pd.concat([final_feature_imp, feature_imp], ignore_index = True)\n",
        "  except:\n",
        "    final_feature_imp = feature_imp\n",
        "\n",
        "# Ordering the data\n",
        "final_feature_imp = final_feature_imp.sort_values('Feature Importance Score', ascending = False).reset_index()\n",
        "final_feature_imp"
      ],
      "metadata": {
        "id": "CSl_4gsBJF9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**We select to apply 10-fold and 5-fold cross-validation again  to see if we find different results**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "nD-mkNjZIvqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# after applying 10 fold cross validation\n",
        "kfold_validation = KFold(n_splits = 10)\n",
        "results = cross_val_score(dtree, attribute, target, cv = kfold_validation)\n",
        "print(results)\n",
        "print ('\\nResults = ', np.mean(results), '+/-', np.std(results))"
      ],
      "metadata": {
        "id": "l1RgJUpFJoDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after applying 5 fold cross validation\n",
        "kfold_validation = KFold(n_splits = 5)\n",
        "results = cross_val_score(dtree, attribute, target, cv = kfold_validation)\n",
        "print(results)\n",
        "print ('\\nResults = ', np.mean(results), '+/-', np.std(results))"
      ],
      "metadata": {
        "id": "EOOlTit3Uau_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Developing a Function for generating Confusion Matrix**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "fvo4FnMTJIhZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "# Confusion Matrix function\n",
        "def plot_confusion_matrix(cm, classes=None, title='Confusion matrix'):\n",
        "  if classes is not None:\n",
        "    sns.heatmap(cm, xticklabels=classes, yticklabels=classes, vmin=0., vmax=1., annot=True, annot_kws={'size':30})\n",
        "  else:\n",
        "    sns.heatmap(cm, vmin=0., vmax=1.)\n",
        "    \n",
        "  plt.title(title)\n",
        "  plt.ylabel('True label')\n",
        "  plt.xlabel('Predicted label')"
      ],
      "metadata": {
        "id": "eFGSE-WpKCTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Visualizing Confusion Matrix graph**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "D9joVh5fJnzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "y_pred = dtree.predict(X_train)\n",
        "\n",
        "# Plotting Confusion Matrix for Training\n",
        "cmatrix = confusion_matrix(y_train, y_pred)"
      ],
      "metadata": {
        "id": "0VYx2xsIKGwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmatrix"
      ],
      "metadata": {
        "id": "VQhzEiraKKYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cmatrix_norm = cmatrix/cmatrix.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cmatrix_norm, classes=dtree.classes_, title='Training confusion')"
      ],
      "metadata": {
        "id": "Umd21UG6KOe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "**Calculating some evaluation metric**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JWVwenFAKfBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating False Positives (FP), False Negatives (FN), True Positives(TP), True Negatices (TN)\n",
        "FP = cmatrix.sum(axis=0) - np.diag(cmatrix)\n",
        "FN = cmatrix.sum(axis=1) - np.diag(cmatrix)\n",
        "TP = np.diag(cmatrix)\n",
        "TN = cmatrix.sum() - (FP + FN + TP)\n",
        "\n",
        "# precision or positive predictive value\n",
        "precision = TP / (TP + FP)\n",
        "print('Precision per class: ', precision)\n",
        "\n",
        "# sensitivity, recall or true predictive rate\n",
        "recall = TP / (TP + FN)\n",
        "print('Recall per class: ', recall)\n",
        "\n",
        "# false positive rate\n",
        "fpr = FP / (FP + TN)\n",
        "print('False positive rate per class: ', fpr)\n",
        "\n",
        "# false negative rate\n",
        "fnr = FN / (TP + FN)\n",
        "print('False negative rate per class: ', fnr)\n",
        "\n",
        "# classification error\n",
        "c_error = (FP + FN) / (TP + FP + FN + TN)\n",
        "print('The classification error of each class: ' ,c_error)\n",
        "\n",
        "# overall accuracy\n",
        "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
        "print('The accuracy of each class: ' ,accuracy)\n",
        "\n",
        "# Averages\n",
        "print('\\nAverage Recall : ' ,recall.sum()/3)\n",
        "print('Average Precision : ' ,precision.sum()/3)\n",
        "print('Average Miss Rate : ' ,fnr.sum()/3)\n",
        "print('Average Classification error : ' ,c_error.sum()/3)\n",
        "print('Average accuracy : ' ,accuracy.sum()/3)"
      ],
      "metadata": {
        "id": "M-FZS-8nKY5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**We got results listed below:**\n",
        "\n",
        "*   Average Recall :  97.05%\n",
        "*   Average Precision :  97.66%\n",
        "*   Average Miss Rate :  2.94%\n",
        "*   Average Classification error :  1.71%\n",
        "*   Average accuracy :  98.28%\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hPahplDWK04q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# ***Random Forest*** \n",
        "\n",
        "---\n",
        "---\n",
        "We want to run the \"Random Forest\" classifier in the dataset. We calculate the best parameters using the gid search and randomized search. Then, Fit these parameters to calculate accuracy for training and testing."
      ],
      "metadata": {
        "id": "vDADXBXQL9Y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest = RandomForestClassifier()\n",
        "# Define the hyperparameters and their ranges\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 5, 10],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "# Create a Random Forest classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Perform grid search using the defined hyperparameters and 5-fold cross-validation\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kTgfkSTURrn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a Random Forest model with the best hyperparameters\n",
        "best_rf = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'],\n",
        "                                  max_depth=grid_search.best_params_['max_depth'],\n",
        "                                  min_samples_split=grid_search.best_params_['min_samples_split'],\n",
        "                                  min_samples_leaf=grid_search.best_params_['min_samples_leaf'])\n",
        "\n",
        "best_rf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "DcxBgBMjUdhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_rf.fit(X_train, y_train)\n",
        "prediction_test = best_rf.predict(X=X_test)\n",
        "# Training Accuracy Of Random Forest\n",
        "print(\"Training Accuracy : \", best_rf.score(X_train, y_train))\n",
        "# Test Accuracy Of Random Forest\n",
        "print(\"Testing Accuracy : \", best_rf.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "f227qqKDUsAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "**Using grid search, we got the result of 100% for training and testing.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "In9cMw8BOHt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the hyperparameters and their distributions\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),\n",
        "    'max_depth': [None, 5, 10, 15, 20],\n",
        "    'min_samples_split': randint(2, 10),\n",
        "    'min_samples_leaf': randint(1, 5)\n",
        "}\n",
        "\n",
        "# Create a Random Forest classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Perform randomized search using the defined hyperparameters and 5-fold cross-validation\n",
        "n_iter_search = 50\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=n_iter_search, cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the randomized search to the data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print out the best hyperparameters and the corresponding mean cross-validation score\n",
        "print(\"Best hyperparameters: \", random_search.best_params_)\n",
        "print(\"Best cross-validation score: {:.2f}\".format(random_search.best_score_))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5cG1N-OhWpwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit a Random Forest model with the best hyperparameters\n",
        "best_rf = RandomForestClassifier(n_estimators=random_search.best_params_['n_estimators'],\n",
        "                                  max_depth=random_search.best_params_['max_depth'],\n",
        "                                  min_samples_split=random_search.best_params_['min_samples_split'],\n",
        "                                  min_samples_leaf=random_search.best_params_['min_samples_leaf'])\n",
        "\n",
        "best_rf.fit(X_train, y_train)\n",
        "prediction_test = best_rf.predict(X=X_test)\n",
        "# Training Accuracy Of Random Forest\n",
        "print(\"Training Accuracy : \", best_rf.score(X_train, y_train))\n",
        "# Test Accuracy Of Random Forest\n",
        "print(\"Testing Accuracy : \", best_rf.score(X_test, y_test))\n"
      ],
      "metadata": {
        "id": "nLXBLJ7pXf6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "**Using Randomized search, we also got the result of 100% for training and testing.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "0Jq4lM7cO3zY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 300, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt','log2']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(5, 100,5)]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 3, 5, 7, 9, 10, 11, 14]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4, 6, 7, 8]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "'max_features': max_features,\n",
        "'max_depth': max_depth,\n",
        "'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf,\n",
        "'criterion':['entropy','gini']\n",
        "}\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "9XNFIyCMYHGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rand_forest = RandomForestClassifier()\n",
        "rand_forest_randomcv = RandomizedSearchCV(estimator=rand_forest, param_distributions=param_dist, n_iter=100, cv=10, verbose=2, random_state=100, n_jobs=-1)\n",
        "# fit the randomized model\n",
        "rand_forest_randomcv.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "-aMeSLXtYQ0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best parameters\n",
        "rand_forest_randomcv.best_params_"
      ],
      "metadata": {
        "id": "fSg3J3GxYUnB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# best estimator\n",
        "rand_forest_randomcv.best_estimator_\n",
        "RandomForestClassifier(max_depth=None, max_features='auto', min_samples_leaf=1,\n",
        " min_samples_split=5, n_estimators=153)\n",
        "best_random_grid = rand_forest_randomcv.best_estimator_\n",
        "y_pred=best_random_grid.predict(X_test)\n",
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(\"Accuracy Score {}\".format(accuracy_score(y_test,y_pred)))\n",
        "print(\"Classification report: \\n{}\".format(classification_report(y_test,y_pred)))"
      ],
      "metadata": {
        "id": "xPDoKRwLYgW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100, 200, 300, 500]\n",
        "max_features = ['auto', 'sqrt', 'log2']\n",
        "max_depths = [None, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15]\n",
        "\n",
        "train_results = []\n",
        "test_results = []\n",
        "\n",
        "# to iterate through all possible combinations\n",
        "for feature, depth in product(max_features, max_depths):\n",
        "    for estimator in n_estimators:\n",
        "        tunned_forest = RandomForestClassifier(n_estimators=estimator,\n",
        "                                                criterion='entropy',\n",
        "                                                max_features=feature,\n",
        "                                                max_depth=depth,\n",
        "                                                n_jobs=1,\n",
        "                                                random_state=30)\n",
        "\n",
        "        tunned_forest.fit(X_train, y_train)\n",
        "        prediction_train = tunned_forest.predict(X=X_train)\n",
        "        roc_auc_train = roc_auc_score(y_train, tunned_forest.predict_proba(X_train), multi_class='ovr')\n",
        "        train_results.append(roc_auc_train)\n",
        "\n",
        "        prediction_test = tunned_forest.predict(X=X_test)\n",
        "        roc_auc_test = roc_auc_score(y_test, tunned_forest.predict_proba(X_test), multi_class='ovr')\n",
        "        test_results.append(roc_auc_test)\n",
        "\n",
        "        # Checking classification accuracy of each tree\n",
        "        print('For n_estimators : ', estimator)\n",
        "        print('Classification accuracy on Train set with max_features = {} and max_depth = {}: Accuracy: = {}'\n",
        "              .format(feature, depth, accuracy_score(y_train, prediction_train)))\n",
        "\n",
        "        print('Classification accuracy on test set with max_features = {} and max_depth = {}: Accuracy: = {}'\n",
        "              .format(feature, depth, accuracy_score(y_test, prediction_test)))\n",
        "        print()\n",
        "\n",
        "        # Generating confusion matrix\n",
        "        c_matrix = confusion_matrix(y_test, prediction_test)\n",
        "        c_matrix_norm = c_matrix / c_matrix.sum(axis=1)[:, np.newaxis]\n"
      ],
      "metadata": {
        "id": "2F-4XKM5aLp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "rand_forest = RandomForestClassifier(n_estimators=500, \n",
        "                                     criterion='entropy',\n",
        "                                     max_features='log2',\n",
        "                                     max_depth=15)\n",
        "rand_forest.fit(X_train, y_train)\n",
        "prediction_test = rand_forest.predict(X_test)\n",
        "prediction_train = rand_forest.predict(X_train)\n",
        "\n",
        "# Training Accuracy Of Random Forest\n",
        "print(\"Training Accuracy : \", rand_forest.score(X_train, y_train))\n",
        "\n",
        "# Test Accuracy Of Random Forest\n",
        "print(\"Testing Accuracy : \", rand_forest.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "bdQwXnVWceht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, prediction_test))"
      ],
      "metadata": {
        "id": "_9lxQe9ukZI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**We got no change in the result by using a different approach in the Randomized search! Now we will check the Importance of features and Visualize the bar graph.**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "3Pz-prDiSWWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# feature scores\n",
        "feature_scores = pd.Series(rand_forest.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
        "feature_scores"
      ],
      "metadata": {
        "id": "VyatSuNokdin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seaborn bar plot\n",
        "sns.barplot(x=feature_scores, y=feature_scores.index)\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PsvauKsAkeid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Defining a function for generating a graph for the confusion matrix for training and testing accuracy**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "dmeAHda2Tn0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n"
      ],
      "metadata": {
        "id": "KuV--KaFoP7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_matrix_rand = confusion_matrix(y_train, prediction_train)\n",
        "c_matrix_norm = c_matrix_rand/c_matrix_rand.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure()\n",
        "plot_confusion_matrix(c_matrix_norm, classes=rand_forest.classes_, title='Classification accuracy on Train set')"
      ],
      "metadata": {
        "id": "BaAAacdwklhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_matrix_rand"
      ],
      "metadata": {
        "id": "Km8twK5jknp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_matrix_rand = confusion_matrix(y_train, prediction_train)\n",
        "c_matrix_norm = c_matrix_rand/c_matrix_rand.sum(axis=1)[:, np.newaxis]\n",
        "plt.figure()\n",
        "plot_confusion_matrix(c_matrix_norm, classes=rand_forest.classes_, title='Classification accuracy on Test set')\n",
        "\n"
      ],
      "metadata": {
        "id": "sOAg_dV2kp7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_matrix_rand"
      ],
      "metadata": {
        "id": "1dGcVixFkqfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# ***KNN*** \n",
        "\n",
        "---\n",
        "---\n",
        "Now, we will run the KNN classifier in the dataset. For different values of k, we want to find the difference between the training and testing accuracy. Later, we will apply it to the scale of instances using MinMaxScaler, StandardScaler, MaxAbsScaler, and RobustScaler. With the scaled value, we want to find the difference between the training and testing accuracy. "
      ],
      "metadata": {
        "id": "CWwTg_rdU2uw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Exploring the dataset. Dividing it into training and testing part.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "LyMYKRIlrrFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Analyzing the dataset\n",
        "new_df.describe()"
      ],
      "metadata": {
        "id": "DVOTsWlbd3yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test splitting, 70% for training & 30% for testing\n",
        "X = new_df.drop(columns = 'Level').values# Input features (attributes)\n",
        "y = new_df['Level'].values # Target vector\n",
        "print('X shape: {}'.format(np.shape(X)))\n",
        "print('y shape: {}'.format(np.shape(y)))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.7, test_size=0.3, random_state=0)"
      ],
      "metadata": {
        "id": "T-bEc2UzjlWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**We will apply it to the model. We will define k values from 1 to 700 neighbors.**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V9nLDAWHsI6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numNeighbors = range(1,701)\n",
        "trainAcc = []\n",
        "testAcc = []\n",
        "for k in numNeighbors:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2, algorithm ='brute')\n",
        "  knn.fit(X_train, y_train)\n",
        "  y_predTrain = knn.predict(X_train)\n",
        "  y_predTest = knn.predict(X_test)\n",
        "  trainAcc.append(accuracy_score(y_train, y_predTrain))\n",
        "  testAcc.append(accuracy_score(y_test, y_predTest))\n",
        "\n",
        "plt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, testAcc, 'bv-')\n",
        "plt.legend(['Training Accuracy','Test Accuracy'])\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "index = 0\n",
        "for i in numNeighbors:\n",
        "  print(\"K = \", numNeighbors[index], \", Training Accuracy = \", trainAcc[index], \" Test Accuracy = \",\n",
        "        testAcc[index], \" Difference = \", np.abs(trainAcc[index]-testAcc[index])*100, \"%\")\n",
        "  index += 1\n",
        "  #8"
      ],
      "metadata": {
        "id": "bLv-97p6hWQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "**For k = 8, training accuracy of 99.71% and testing accuracy of 99.66% had a difference of 0.047% approximately. We have ignored the k value of 1 & 2 since these can be noisy.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "4W5per9stQbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**We will apply StandardScaler to scale data and train it to KNN classifier**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D93p39tUu7Zf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Standardize the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the KNN classifier using the scaled data\n",
        "knn = KNeighborsClassifier(metric='minkowski', p=2)\n",
        "knn.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "xMefv1jTm4Pb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numNeighbors = range(1,701)\n",
        "trainAcc = []\n",
        "testAcc = []\n",
        "for k in numNeighbors:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2, algorithm ='brute')\n",
        "  knn.fit(X_train_scaled, y_train)\n",
        "  y_predTrain = knn.predict(X_train_scaled)\n",
        "  y_predTest = knn.predict(X_test_scaled)\n",
        "  trainAcc.append(accuracy_score(y_train, y_predTrain))\n",
        "  testAcc.append(accuracy_score(y_test, y_predTest))\n",
        "\n",
        "plt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, testAcc, 'bv-')\n",
        "plt.legend(['Training Accuracy','Test Accuracy'])\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "index = 0\n",
        "for i in numNeighbors:\n",
        "  print(\"K = \", numNeighbors[index], \", Training Accuracy = \", trainAcc[index], \" Test Accuracy = \",\n",
        "        testAcc[index], \" Difference = \", np.abs(trainAcc[index]-testAcc[index])*100, \"%\")\n",
        "  index += 1"
      ],
      "metadata": {
        "id": "9idzPR1dnQSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**For k = 9, training accuracy of 99.42% and testing accuracy of 98.00% had a difference of 1.42% approximately. We have ignored the k value of (1-8) since these can be noisy.**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "GaF8bXHlvcEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "**Now, We will apply MinMaxScaler to scale data and train it to KNN classifier**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vxxCRJA5vVhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the KNN classifier using the scaled data\n",
        "knn = KNeighborsClassifier(metric='minkowski', p=2)\n",
        "knn.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "2CeyuLPvnpM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numNeighbors = range(1,701)\n",
        "trainAcc = []\n",
        "testAcc = []\n",
        "for k in numNeighbors:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2, algorithm ='brute')\n",
        "  knn.fit(X_train_scaled, y_train)\n",
        "  y_predTrain = knn.predict(X_train_scaled)\n",
        "  y_predTest = knn.predict(X_test_scaled)\n",
        "  trainAcc.append(accuracy_score(y_train, y_predTrain))\n",
        "  testAcc.append(accuracy_score(y_test, y_predTest))\n",
        "\n",
        "plt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, testAcc, 'bv-')\n",
        "plt.legend(['Training Accuracy','Test Accuracy'])\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "index = 0\n",
        "for i in numNeighbors:\n",
        "  print(\"K = \", numNeighbors[index], \", Training Accuracy = \", trainAcc[index], \" Test Accuracy = \",\n",
        "        testAcc[index], \" Difference = \", np.abs(trainAcc[index]-testAcc[index])*100, \"%\")\n",
        "  index += 1"
      ],
      "metadata": {
        "id": "Aw63IRl4oE4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**We got same result as Standardscaler.For k =3 , the model seems overfitted.**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**After then,We will apply MaxAbsScaler to scale data and train it to KNN classifier**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mLa8PHpLwKcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MaxAbsScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the KNN classifier using the scaled data\n",
        "knn = KNeighborsClassifier(metric='minkowski', p=2)\n",
        "knn.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "caD7Bz5lryD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numNeighbors = range(1,701)\n",
        "trainAcc = []\n",
        "testAcc = []\n",
        "for k in numNeighbors:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2, algorithm ='brute')\n",
        "  knn.fit(X_train_scaled, y_train)\n",
        "  y_predTrain = knn.predict(X_train_scaled)\n",
        "  y_predTest = knn.predict(X_test_scaled)\n",
        "  trainAcc.append(accuracy_score(y_train, y_predTrain))\n",
        "  testAcc.append(accuracy_score(y_test, y_predTest))\n",
        "\n",
        "plt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, testAcc, 'bv-')\n",
        "plt.legend(['Training Accuracy','Test Accuracy'])\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "index = 0\n",
        "for i in numNeighbors:\n",
        "  print(\"K = \", numNeighbors[index], \", Training Accuracy = \", trainAcc[index], \" Test Accuracy = \",\n",
        "        testAcc[index], \" Difference = \", np.abs(trainAcc[index]-testAcc[index])*100, \"%\")\n",
        "  index += 1"
      ],
      "metadata": {
        "id": "Eufk6P1yr7SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**No change for the MinMaxScaler!**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Lastly, We will apply RobustScaler to scale data and train it to KNN classifier**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RXHAZb7yxGit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the KNN classifier using the scaled data\n",
        "knn = KNeighborsClassifier(metric='minkowski', p=2)\n",
        "knn.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "vpxAPwFMsdvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numNeighbors = range(1,701)\n",
        "trainAcc = []\n",
        "testAcc = []\n",
        "for k in numNeighbors:\n",
        "  knn = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2, algorithm ='brute')\n",
        "  knn.fit(X_train_scaled, y_train)\n",
        "  y_predTrain = knn.predict(X_train_scaled)\n",
        "  y_predTest = knn.predict(X_test_scaled)\n",
        "  trainAcc.append(accuracy_score(y_train, y_predTrain))\n",
        "  testAcc.append(accuracy_score(y_test, y_predTest))\n",
        "\n",
        "plt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, testAcc, 'bv-')\n",
        "plt.legend(['Training Accuracy','Test Accuracy'])\n",
        "plt.xlabel('Number of neighbors')\n",
        "plt.ylabel('Accuracy')\n",
        "index = 0\n",
        "for i in numNeighbors:\n",
        "  print(\"K = \", numNeighbors[index], \", Training Accuracy = \", trainAcc[index], \" Test Accuracy = \",\n",
        "        testAcc[index], \" Difference = \", np.abs(trainAcc[index]-testAcc[index])*100, \"%\")\n",
        "  index += 1"
      ],
      "metadata": {
        "id": "VyC5otNWsnzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Same result!**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PxQMpFBtzH2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# ***Naive Bayes*** \n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "OVUNMpWaDKKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# ***Support Vector Machine*** \n",
        "\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "WO6ZFE1SDhFh"
      }
    }
  ]
}